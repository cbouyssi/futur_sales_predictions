{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Kaggle Challenge : Predict Future Sales - Notebook</h2>\n",
    "link : https://www.kaggle.com/c/competitive-data-science-predict-future-sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Common methods used for models evaluation / hyperparameters otpimisation</h4>\n",
    "This method takes the result of the RandomizedSearch/GridSearch and report the scores of the 'n' first best models, with the according parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initializing dataframes</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data repositories\n",
    "data_folder = \"data\"\n",
    "results_folder = \"results\"\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    \n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# Filenames\n",
    "shops_filename = \"shops.csv\"\n",
    "items_filename = \"items.csv\"\n",
    "item_categories_filename = \"item_categories.csv\"\n",
    "train_filename = \"sales_train.csv.gz\"\n",
    "eval_filname = \"test.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "shops = pd.read_csv(data_folder+\"/\"+shops_filename)\n",
    "items = pd.read_csv(data_folder+\"/\"+items_filename)\n",
    "item_categories = pd.read_csv(data_folder+\"/\"+item_categories_filename)\n",
    "train = pd.read_csv(data_folder+\"/\"+train_filename, compression='gzip')\n",
    "eval_df = pd.read_csv(data_folder+\"/\"+eval_filname, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Monthly prediction</h2>\n",
    "<h5>In this first method I will aggregate the sales of every product on a month basis and predict the number of items sold per shop, per month</h5>\n",
    "<h3>Preprocessing of the train / test dataset</h3>\n",
    "<h4>Training dataset</h4>\n",
    "Shape : [date, date_block_num, shop_id, item_id, item_price, item_cnt_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation of the price for each item group by shop item and date_block_num\n",
    "grouper = train.groupby(['date_block_num', 'shop_id', 'item_id'], as_index=False).agg({'item_price': 'mean', 'item_cnt_day': 'count'})\n",
    "# Features\n",
    "X = grouper.loc[:, grouper.columns != 'item_cnt_day']\n",
    "# Target\n",
    "Y = grouper['item_cnt_day'].rename({'item_cnt_day':'item_cnt_month'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Testing dataset</h4>\n",
    "Shape : [shop_id, item_id]\n",
    "We'll have to associate the price of each item and add a column for the date_block_num (which will be the month number of the predictions : 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month number column\n",
    "eval_df['date_block_num'] = eval_df['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a [\"shop_id\", \"item_id\", \"item_price\"] dataframe to join with test dataset\n",
    "prices = train[['shop_id', 'item_id', 'item_price']].drop_duplicates()\n",
    "prices = prices.groupby(['shop_id', 'item_id'], as_index=False).agg({'item_price':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prices \n",
    "eval_df_with_prices = pd.merge(eval_df, prices, on=['shop_id', 'item_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ('shop_id', 'item_id') that weren't in the training dataset, we calculate the average price for each 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_with_prices['item_price'] = eval_df_with_prices.groupby('item_id')['item_price'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining rows without 'item_price', we can't use anything besides : Mean prices of all items OR mean prices of all items of the same category.\n",
    "<h4>--><h/4> Method 1 : Average price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, shop_id, item_id, date_block_num, item_price]\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_with_prices['item_price'] = eval_df_with_prices['item_price'].fillna('mean')\n",
    "# We make sure that no rows are left with an empty 'item_price'\n",
    "eval_df_with_prices.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Validation / Optimization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training df into 'train' and 'test' df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Hyper parameters tunning\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_best_scores(search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation</h3>\n",
    "We can now pick the model with the best results from the list given by 'report_best_scores', train it with the entire training data and make the predictions for the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(colsample_bytree=0.8045997961875188, gamma=0.04808827554571038, learning_rate=0.31215697934688114, max_depth=5, n_estimators=138, subsample=0.9746919954946938)\n",
    "xgb_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions - The columns must be in the same order than the one used for training\n",
    "predictions = xgb_model.predict(eval_df_with_prices[['date_block_num', 'shop_id', 'item_id', 'item_price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(results_folder+\"/\"+\"results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
